{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Setting Things Up**\n",
        "\n",
        "**1 If you haven't already, please hit :**\n",
        "\n",
        "`File > Save a Copy in Drive`\n",
        "\n",
        "**to copy this notebook to your Google drive, and work on a copy. If you don't do this, your changes won't be saved!**\n",
        "\n",
        "\n",
        "**2 In order to use a GPU with your notebook, select :**\n",
        "\n",
        "`Runtime > Change runtime type`\n",
        "\n",
        "**menu, and then set the hardware accelerator dropdown to GPU. This can significantly speed up the training process.**\n",
        "\n",
        "**3 In order to have enough memory with your notebook, select :**\n",
        "\n",
        "`Runtime > Change runtime type`\n",
        "\n",
        "**menu, and then select High-RAM in the Runtime shape dropdown.**\n",
        "\n",
        "To facilitate your initial progress, we have included a ready-to-use code on Google Colab for this problem. It allows you to get started immediately. Additionally, if you prefer not to use Google Colab and prefer setting up your own programming environment or employing alternative methods, the provided files and code will still be valuable.\n",
        "\n",
        "**PS:You need manually install the `tensorflow_text` and `tf-models-official` libraries**\n",
        "\n",
        "\n",
        "**PS:You also need manually load pretrained Bert model weights `bert_en_uncased_preprocess_3` and `small_bert_bert_en_uncased_L-4_H-512_A-8_2` into `model weight` folder. The Bert model weights can be found in our datasets.**"
      ],
      "metadata": {
        "id": "ePMokB56crvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvdTPQfzmnAm",
        "outputId": "2e9d600d-7a7d-4490-8814-7a9631d11604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun 21 07:41:38 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    45W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DwlxLjxm5fG",
        "outputId": "688b265c-7113-437b-e12d-b6c0de4d6e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text"
      ],
      "metadata": {
        "id": "GEWN4ueWzlvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb6fa469-efc2-45c3-8821-d518442276b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.13.0)\n",
            "Requirement already satisfied: tensorflow<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow_text) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.13,>=2.12.0->tensorflow_text) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow_text) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow_text) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow_text) (3.2.2)\n",
            "Installing collected packages: tensorflow_text\n",
            "Successfully installed tensorflow_text-2.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-models-official"
      ],
      "metadata": {
        "id": "J-x8JrNrzpDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb29181d-3cb2-4eb7-8681-e43ba0cf5b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf-models-official in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (0.29.34)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (8.4.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (2.84.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (2.2.4)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.5.13)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.23.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (4.7.0.72)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.5.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (2.0.6)\n",
            "Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (5.4.1)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.10.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (0.1.99)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (0.20.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (4.9.2)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (0.13.0)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (0.7.5)\n",
            "Requirement already satisfied: tensorflow-text~=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (2.12.1)\n",
            "Requirement already satisfied: tensorflow~=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (2.12.0)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.1.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.21.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.11.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (4.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (1.26.15)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official) (2022.7.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official) (0.32.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (3.0.9)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official) (4.9)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official) (2.7.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official) (2022.10.31)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official) (0.8.10)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official) (4.9.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official) (1.2.2)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons->tf-models-official) (2.13.3)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (0.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (8.1.3)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (1.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (1.13.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.12.0->tf-models-official) (0.40.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official) (5.12.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official) (3.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official) (1.59.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official) (5.3.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tf-models-official) (0.1.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (3.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (2.3.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (2.1.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*-coding:utf8 -*-\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "from keras.optimizers import RMSprop, Adam, SGD\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras import Model, Input, layers, regularizers\n",
        "from keras.models import load_model\n",
        "from keras import activations\n"
      ],
      "metadata": {
        "id": "r9f3jnrspEse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dffd90b-8ae6-47e1-cc43-cbe7332d032e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# change to your personal project address\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/Vehicle Rating Prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjHBjkEcphmW",
        "outputId": "5fe3c903-b100-4fda-910c-580d75b10c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/Vehicle Rating Prediction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1 Data Processing**"
      ],
      "metadata": {
        "id": "VU1zRMz61Ojb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train data shuffle index\n",
        "num1 = 2055\n",
        "idx1 = tf.range(num1)\n",
        "idx1 = tf.random.shuffle(idx1)\n",
        "# print(idx1)\n",
        "# print(idx1[0])\n",
        "with tf.compat.v1.Session():\n",
        "    index1 = idx1.numpy()\n",
        "print(index1.shape)\n",
        "# print(index1[0])\n",
        "\n",
        "# validation data shuffle index\n",
        "num2 = 258\n",
        "idx2 = tf.range(num2)\n",
        "idx2 = tf.random.shuffle(idx2)\n",
        "# print(idx2)\n",
        "# print(idx2[0])\n",
        "with tf.compat.v1.Session():\n",
        "    index2 = idx2.numpy()\n",
        "print(index2.shape)\n",
        "# print(index2[0])\n",
        "\n",
        "# test data shuffle index\n",
        "num3 = 258\n",
        "idx3 = tf.range(num3)\n",
        "idx3 = tf.random.shuffle(idx3)\n",
        "# print(idx3)\n",
        "# print(idx3[0])\n",
        "with tf.compat.v1.Session():\n",
        "    index3 = idx3.numpy()\n",
        "print(index3.shape)\n",
        "# print(index3[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNRtXl_57LXw",
        "outputId": "cc034330-60bd-4e1c-f08e-282f97e5b862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2055,)\n",
            "(258,)\n",
            "(258,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "var = \"total score\"\n",
        "# var = \"safety score\"\n",
        "# var = \"performance score\"\n",
        "# var = \"interior score\"\n",
        "# var = \"critics score\""
      ],
      "metadata": {
        "id": "3hZgE12c6fd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# load the text data\n",
        "var_name = 'data split ' + var\n",
        "\n",
        "sketch1 = pd.read_csv('text_data.csv', encoding='latin1')\n",
        "# print(sketch1.shape)\n",
        "# print(sketch1)\n",
        "# print(sketch1[var])\n",
        "train_df = sketch1[sketch1[var_name] == 1]\n",
        "val_df = sketch1[sketch1[var_name] == 2]\n",
        "test_df = sketch1[sketch1[var_name] == 3]\n",
        "# print(train_df.shape)\n",
        "# print(train_df)\n",
        "\n",
        "sketch2 = train_df.astype({\"text\": str})\n",
        "text1 = list(sketch2['text'])\n",
        "\n",
        "sketch3 = val_df.astype({\"text\": str})\n",
        "text2 = list(sketch3['text'])\n",
        "\n",
        "sketch4 = test_df.astype({\"text\": str})\n",
        "text3 = list(sketch4['text'])\n",
        "\n",
        "\n",
        "train_text = [text1[i] for i in index1]\n",
        "x_train_text = tf.constant(train_text)\n",
        "\n",
        "validation_text = [text2[i] for i in index2]\n",
        "x_validation_text = tf.constant(validation_text)\n",
        "\n",
        "test_text = [text3[i] for i in index3]\n",
        "x_test_text = tf.constant(test_text)\n",
        "# print(len(train_text))\n",
        "# print(train_text[0])\n",
        "\n",
        "y_value = var\n",
        "y_train_origin = list(train_df[y_value])\n",
        "y_train = np.array([y_train_origin[i] for i in index1])\n",
        "y_val_origin = list(val_df[y_value])\n",
        "y_val = np.array([y_val_origin[i] for i in index2])\n",
        "y_test_origin = list(test_df[y_value])\n",
        "y_test = np.array([y_test_origin[i] for i in index3])\n",
        "# print(y_train.shape)\n",
        "# print(y_train)\n",
        "# print(y_val.shape)\n",
        "# print(y_val)\n",
        "# print(y_test.shape)\n",
        "# print(y_test)\n"
      ],
      "metadata": {
        "id": "7wW8edUQpS9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2 Construct Text Model**"
      ],
      "metadata": {
        "id": "nhXOTGUu3-fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bert model\n",
        "\n",
        "epochs = 200\n",
        "steps_per_epoch = 80\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "\n",
        "a = 0.05\n",
        "num_warmup_steps = int(a * num_train_steps)\n",
        "init_lr = 5e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr, num_train_steps=num_train_steps, num_warmup_steps=num_warmup_steps, optimizer_type='adamw')\n",
        "\n",
        "text_input = Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessing_layer = hub.KerasLayer(\"model weight/bert_en_uncased_preprocess_3\", name='preprocessing')\n",
        "encoder_inputs = preprocessing_layer(text_input)\n",
        "encoder = hub.KerasLayer(\"model weight/small_bert_bert_en_uncased_L-4_H-512_A-8_2\", trainable=True, name='BERT_encoder')\n",
        "outputs = encoder(encoder_inputs)\n",
        "net = outputs['pooled_output']\n",
        "net = layers.Dropout(0.1, name='text_dropout_after_Bert')(net)\n",
        "# last_second_layer = last2\n",
        "net = layers.Dense(100, activation='relu', name='text_dense_last2')(net)\n",
        "# net = layers.Dropout(0.1)(net)\n",
        "out1y = layers.Dense(1, name='text_out1y')(net)\n",
        "model = Model(text_input, out1y, name='Text_Model')\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse'), 'mse', 'mae'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "zUMdghzwDnCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1990a2da-14d9-447b-be7d-e459e6663491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Text_Model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprocessing (KerasLayer)     {'input_word_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128),                                                          \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'encoder_outputs':  28763649    ['preprocessing[0][0]',          \n",
            "                                 [(None, 128, 512),               'preprocessing[0][1]',          \n",
            "                                 (None, 128, 512),                'preprocessing[0][2]']          \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 512),                                                       \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 'default': (None,                                                \n",
            "                                512)}                                                             \n",
            "                                                                                                  \n",
            " text_dropout_after_Bert (Dropo  (None, 512)         0           ['BERT_encoder[0][5]']           \n",
            " ut)                                                                                              \n",
            "                                                                                                  \n",
            " text_dense_last2 (Dense)       (None, 100)          51300       ['text_dropout_after_Bert[0][0]']\n",
            "                                                                                                  \n",
            " text_out1y (Dense)             (None, 1)            101         ['text_dense_last2[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,815,050\n",
            "Trainable params: 28,815,049\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 200\n",
        "steps_per_epoch = 80\n",
        "batch_size = 32\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=20, monitor=\"val_loss\", restore_best_weights=True, verbose=1)"
      ],
      "metadata": {
        "id": "eFxraheoCNnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x_train_text,\n",
        "    y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=(x_validation_text, y_val),\n",
        "    callbacks=[early_stopping_callback]\n",
        ")\n",
        "\n",
        "print(history)"
      ],
      "metadata": {
        "id": "Qf8QBHfQqmDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f509a63-47e7-4fc2-871c-1724f7d9b0c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "80/80 [==============================] - 18s 82ms/step - loss: 0.1456 - rmse: 0.3816 - mse: 0.1456 - mae: 0.3046 - val_loss: 0.0376 - val_rmse: 0.1940 - val_mse: 0.0376 - val_mae: 0.1535\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.0740 - rmse: 0.2720 - mse: 0.0740 - mae: 0.2160 - val_loss: 0.0236 - val_rmse: 0.1538 - val_mse: 0.0236 - val_mae: 0.1242\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0428 - rmse: 0.2068 - mse: 0.0428 - mae: 0.1638 - val_loss: 0.0139 - val_rmse: 0.1181 - val_mse: 0.0139 - val_mae: 0.0926\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.0297 - rmse: 0.1724 - mse: 0.0297 - mae: 0.1373 - val_loss: 0.0128 - val_rmse: 0.1131 - val_mse: 0.0128 - val_mae: 0.0905\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0215 - rmse: 0.1467 - mse: 0.0215 - mae: 0.1155 - val_loss: 0.0102 - val_rmse: 0.1010 - val_mse: 0.0102 - val_mae: 0.0772\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.0152 - rmse: 0.1232 - mse: 0.0152 - mae: 0.0970 - val_loss: 0.0085 - val_rmse: 0.0920 - val_mse: 0.0085 - val_mae: 0.0708\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.0129 - rmse: 0.1135 - mse: 0.0129 - mae: 0.0893 - val_loss: 0.0082 - val_rmse: 0.0905 - val_mse: 0.0082 - val_mae: 0.0693\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.0114 - rmse: 0.1068 - mse: 0.0114 - mae: 0.0844 - val_loss: 0.0083 - val_rmse: 0.0912 - val_mse: 0.0083 - val_mae: 0.0697\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0103 - rmse: 0.1015 - mse: 0.0103 - mae: 0.0793 - val_loss: 0.0085 - val_rmse: 0.0925 - val_mse: 0.0085 - val_mae: 0.0708\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.0093 - rmse: 0.0966 - mse: 0.0093 - mae: 0.0761 - val_loss: 0.0100 - val_rmse: 0.0999 - val_mse: 0.0100 - val_mae: 0.0801\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0084 - rmse: 0.0915 - mse: 0.0084 - mae: 0.0718 - val_loss: 0.0092 - val_rmse: 0.0959 - val_mse: 0.0092 - val_mae: 0.0743\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.0078 - rmse: 0.0881 - mse: 0.0078 - mae: 0.0692 - val_loss: 0.0070 - val_rmse: 0.0839 - val_mse: 0.0070 - val_mae: 0.0642\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0068 - rmse: 0.0827 - mse: 0.0068 - mae: 0.0657 - val_loss: 0.0069 - val_rmse: 0.0830 - val_mse: 0.0069 - val_mae: 0.0632\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.0064 - rmse: 0.0800 - mse: 0.0064 - mae: 0.0627 - val_loss: 0.0075 - val_rmse: 0.0867 - val_mse: 0.0075 - val_mae: 0.0666\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.0056 - rmse: 0.0750 - mse: 0.0056 - mae: 0.0592 - val_loss: 0.0078 - val_rmse: 0.0884 - val_mse: 0.0078 - val_mae: 0.0685\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0054 - rmse: 0.0737 - mse: 0.0054 - mae: 0.0587 - val_loss: 0.0089 - val_rmse: 0.0945 - val_mse: 0.0089 - val_mae: 0.0742\n",
            "Epoch 17/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0048 - rmse: 0.0693 - mse: 0.0048 - mae: 0.0551 - val_loss: 0.0071 - val_rmse: 0.0845 - val_mse: 0.0071 - val_mae: 0.0642\n",
            "Epoch 18/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.0043 - rmse: 0.0654 - mse: 0.0043 - mae: 0.0520 - val_loss: 0.0096 - val_rmse: 0.0981 - val_mse: 0.0096 - val_mae: 0.0777\n",
            "Epoch 19/200\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.0042 - rmse: 0.0648 - mse: 0.0042 - mae: 0.0514 - val_loss: 0.0068 - val_rmse: 0.0826 - val_mse: 0.0068 - val_mae: 0.0634\n",
            "Epoch 20/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0039 - rmse: 0.0626 - mse: 0.0039 - mae: 0.0497 - val_loss: 0.0067 - val_rmse: 0.0819 - val_mse: 0.0067 - val_mae: 0.0623\n",
            "Epoch 21/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0033 - rmse: 0.0578 - mse: 0.0033 - mae: 0.0462 - val_loss: 0.0081 - val_rmse: 0.0898 - val_mse: 0.0081 - val_mae: 0.0699\n",
            "Epoch 22/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.0032 - rmse: 0.0567 - mse: 0.0032 - mae: 0.0449 - val_loss: 0.0086 - val_rmse: 0.0927 - val_mse: 0.0086 - val_mae: 0.0723\n",
            "Epoch 23/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0030 - rmse: 0.0552 - mse: 0.0030 - mae: 0.0434 - val_loss: 0.0066 - val_rmse: 0.0814 - val_mse: 0.0066 - val_mae: 0.0620\n",
            "Epoch 24/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.0027 - rmse: 0.0517 - mse: 0.0027 - mae: 0.0409 - val_loss: 0.0070 - val_rmse: 0.0838 - val_mse: 0.0070 - val_mae: 0.0627\n",
            "Epoch 25/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.0027 - rmse: 0.0519 - mse: 0.0027 - mae: 0.0413 - val_loss: 0.0068 - val_rmse: 0.0825 - val_mse: 0.0068 - val_mae: 0.0633\n",
            "Epoch 26/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0025 - rmse: 0.0499 - mse: 0.0025 - mae: 0.0397 - val_loss: 0.0085 - val_rmse: 0.0924 - val_mse: 0.0085 - val_mae: 0.0730\n",
            "Epoch 27/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0023 - rmse: 0.0477 - mse: 0.0023 - mae: 0.0378 - val_loss: 0.0067 - val_rmse: 0.0822 - val_mse: 0.0067 - val_mae: 0.0630\n",
            "Epoch 28/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0022 - rmse: 0.0472 - mse: 0.0022 - mae: 0.0378 - val_loss: 0.0071 - val_rmse: 0.0841 - val_mse: 0.0071 - val_mae: 0.0646\n",
            "Epoch 29/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0021 - rmse: 0.0459 - mse: 0.0021 - mae: 0.0365 - val_loss: 0.0068 - val_rmse: 0.0824 - val_mse: 0.0068 - val_mae: 0.0633\n",
            "Epoch 30/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0020 - rmse: 0.0446 - mse: 0.0020 - mae: 0.0357 - val_loss: 0.0067 - val_rmse: 0.0818 - val_mse: 0.0067 - val_mae: 0.0626\n",
            "Epoch 31/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0020 - rmse: 0.0447 - mse: 0.0020 - mae: 0.0361 - val_loss: 0.0067 - val_rmse: 0.0818 - val_mse: 0.0067 - val_mae: 0.0626\n",
            "Epoch 32/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0021 - rmse: 0.0457 - mse: 0.0021 - mae: 0.0361 - val_loss: 0.0077 - val_rmse: 0.0878 - val_mse: 0.0077 - val_mae: 0.0675\n",
            "Epoch 33/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.0020 - rmse: 0.0444 - mse: 0.0020 - mae: 0.0352 - val_loss: 0.0066 - val_rmse: 0.0810 - val_mse: 0.0066 - val_mae: 0.0622\n",
            "Epoch 34/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.0017 - rmse: 0.0418 - mse: 0.0017 - mae: 0.0333 - val_loss: 0.0069 - val_rmse: 0.0830 - val_mse: 0.0069 - val_mae: 0.0632\n",
            "Epoch 35/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0016 - rmse: 0.0397 - mse: 0.0016 - mae: 0.0314 - val_loss: 0.0066 - val_rmse: 0.0812 - val_mse: 0.0066 - val_mae: 0.0630\n",
            "Epoch 36/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.0017 - rmse: 0.0418 - mse: 0.0017 - mae: 0.0328 - val_loss: 0.0069 - val_rmse: 0.0829 - val_mse: 0.0069 - val_mae: 0.0642\n",
            "Epoch 37/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0017 - rmse: 0.0413 - mse: 0.0017 - mae: 0.0328 - val_loss: 0.0065 - val_rmse: 0.0809 - val_mse: 0.0065 - val_mae: 0.0615\n",
            "Epoch 38/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0015 - rmse: 0.0387 - mse: 0.0015 - mae: 0.0308 - val_loss: 0.0066 - val_rmse: 0.0813 - val_mse: 0.0066 - val_mae: 0.0618\n",
            "Epoch 39/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.0016 - rmse: 0.0394 - mse: 0.0016 - mae: 0.0313 - val_loss: 0.0070 - val_rmse: 0.0838 - val_mse: 0.0070 - val_mae: 0.0640\n",
            "Epoch 40/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.0014 - rmse: 0.0377 - mse: 0.0014 - mae: 0.0300 - val_loss: 0.0066 - val_rmse: 0.0809 - val_mse: 0.0066 - val_mae: 0.0619\n",
            "Epoch 41/200\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 0.0014 - rmse: 0.0368 - mse: 0.0014 - mae: 0.0292 - val_loss: 0.0065 - val_rmse: 0.0806 - val_mse: 0.0065 - val_mae: 0.0621\n",
            "Epoch 42/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0013 - rmse: 0.0362 - mse: 0.0013 - mae: 0.0287 - val_loss: 0.0064 - val_rmse: 0.0799 - val_mse: 0.0064 - val_mae: 0.0603\n",
            "Epoch 43/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0013 - rmse: 0.0354 - mse: 0.0013 - mae: 0.0281 - val_loss: 0.0065 - val_rmse: 0.0808 - val_mse: 0.0065 - val_mae: 0.0617\n",
            "Epoch 44/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0013 - rmse: 0.0366 - mse: 0.0013 - mae: 0.0293 - val_loss: 0.0062 - val_rmse: 0.0789 - val_mse: 0.0062 - val_mae: 0.0600\n",
            "Epoch 45/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.0012 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0277 - val_loss: 0.0066 - val_rmse: 0.0815 - val_mse: 0.0066 - val_mae: 0.0624\n",
            "Epoch 46/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0012 - rmse: 0.0349 - mse: 0.0012 - mae: 0.0277 - val_loss: 0.0063 - val_rmse: 0.0794 - val_mse: 0.0063 - val_mae: 0.0605\n",
            "Epoch 47/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.0013 - rmse: 0.0362 - mse: 0.0013 - mae: 0.0288 - val_loss: 0.0064 - val_rmse: 0.0797 - val_mse: 0.0064 - val_mae: 0.0606\n",
            "Epoch 48/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0011 - rmse: 0.0337 - mse: 0.0011 - mae: 0.0267 - val_loss: 0.0064 - val_rmse: 0.0802 - val_mse: 0.0064 - val_mae: 0.0611\n",
            "Epoch 49/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.0012 - rmse: 0.0346 - mse: 0.0012 - mae: 0.0273 - val_loss: 0.0066 - val_rmse: 0.0813 - val_mse: 0.0066 - val_mae: 0.0624\n",
            "Epoch 50/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0010 - rmse: 0.0322 - mse: 0.0010 - mae: 0.0259 - val_loss: 0.0063 - val_rmse: 0.0795 - val_mse: 0.0063 - val_mae: 0.0610\n",
            "Epoch 51/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0011 - rmse: 0.0326 - mse: 0.0011 - mae: 0.0258 - val_loss: 0.0064 - val_rmse: 0.0797 - val_mse: 0.0064 - val_mae: 0.0611\n",
            "Epoch 52/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.0010 - rmse: 0.0323 - mse: 0.0010 - mae: 0.0257 - val_loss: 0.0064 - val_rmse: 0.0798 - val_mse: 0.0064 - val_mae: 0.0604\n",
            "Epoch 53/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.0011 - rmse: 0.0338 - mse: 0.0011 - mae: 0.0268 - val_loss: 0.0064 - val_rmse: 0.0803 - val_mse: 0.0064 - val_mae: 0.0607\n",
            "Epoch 54/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0010 - rmse: 0.0322 - mse: 0.0010 - mae: 0.0255 - val_loss: 0.0065 - val_rmse: 0.0806 - val_mse: 0.0065 - val_mae: 0.0621\n",
            "Epoch 55/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 9.7654e-04 - rmse: 0.0312 - mse: 9.7654e-04 - mae: 0.0247 - val_loss: 0.0064 - val_rmse: 0.0798 - val_mse: 0.0064 - val_mae: 0.0605\n",
            "Epoch 56/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 0.0010 - rmse: 0.0319 - mse: 0.0010 - mae: 0.0253 - val_loss: 0.0063 - val_rmse: 0.0795 - val_mse: 0.0063 - val_mae: 0.0600\n",
            "Epoch 57/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 9.0892e-04 - rmse: 0.0301 - mse: 9.0892e-04 - mae: 0.0238 - val_loss: 0.0063 - val_rmse: 0.0796 - val_mse: 0.0063 - val_mae: 0.0607\n",
            "Epoch 58/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 0.0010 - rmse: 0.0318 - mse: 0.0010 - mae: 0.0250 - val_loss: 0.0063 - val_rmse: 0.0791 - val_mse: 0.0063 - val_mae: 0.0594\n",
            "Epoch 59/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 0.0012 - rmse: 0.0340 - mse: 0.0012 - mae: 0.0270 - val_loss: 0.0064 - val_rmse: 0.0801 - val_mse: 0.0064 - val_mae: 0.0611\n",
            "Epoch 60/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 9.4823e-04 - rmse: 0.0308 - mse: 9.4823e-04 - mae: 0.0248 - val_loss: 0.0064 - val_rmse: 0.0799 - val_mse: 0.0064 - val_mae: 0.0603\n",
            "Epoch 61/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 8.7265e-04 - rmse: 0.0295 - mse: 8.7265e-04 - mae: 0.0234 - val_loss: 0.0062 - val_rmse: 0.0788 - val_mse: 0.0062 - val_mae: 0.0600\n",
            "Epoch 62/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 7.9903e-04 - rmse: 0.0283 - mse: 7.9903e-04 - mae: 0.0221 - val_loss: 0.0065 - val_rmse: 0.0804 - val_mse: 0.0065 - val_mae: 0.0609\n",
            "Epoch 63/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 8.5776e-04 - rmse: 0.0293 - mse: 8.5776e-04 - mae: 0.0232 - val_loss: 0.0063 - val_rmse: 0.0794 - val_mse: 0.0063 - val_mae: 0.0599\n",
            "Epoch 64/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 9.0934e-04 - rmse: 0.0302 - mse: 9.0934e-04 - mae: 0.0235 - val_loss: 0.0063 - val_rmse: 0.0796 - val_mse: 0.0063 - val_mae: 0.0597\n",
            "Epoch 65/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 8.3646e-04 - rmse: 0.0289 - mse: 8.3646e-04 - mae: 0.0229 - val_loss: 0.0062 - val_rmse: 0.0786 - val_mse: 0.0062 - val_mae: 0.0591\n",
            "Epoch 66/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 8.1250e-04 - rmse: 0.0285 - mse: 8.1250e-04 - mae: 0.0227 - val_loss: 0.0061 - val_rmse: 0.0781 - val_mse: 0.0061 - val_mae: 0.0590\n",
            "Epoch 67/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 9.7777e-04 - rmse: 0.0313 - mse: 9.7777e-04 - mae: 0.0248 - val_loss: 0.0060 - val_rmse: 0.0776 - val_mse: 0.0060 - val_mae: 0.0588\n",
            "Epoch 68/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 7.9053e-04 - rmse: 0.0281 - mse: 7.9053e-04 - mae: 0.0220 - val_loss: 0.0061 - val_rmse: 0.0781 - val_mse: 0.0061 - val_mae: 0.0588\n",
            "Epoch 69/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 7.2410e-04 - rmse: 0.0269 - mse: 7.2410e-04 - mae: 0.0214 - val_loss: 0.0060 - val_rmse: 0.0773 - val_mse: 0.0060 - val_mae: 0.0589\n",
            "Epoch 70/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 7.1921e-04 - rmse: 0.0268 - mse: 7.1921e-04 - mae: 0.0212 - val_loss: 0.0060 - val_rmse: 0.0774 - val_mse: 0.0060 - val_mae: 0.0583\n",
            "Epoch 71/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 7.7844e-04 - rmse: 0.0279 - mse: 7.7844e-04 - mae: 0.0222 - val_loss: 0.0059 - val_rmse: 0.0769 - val_mse: 0.0059 - val_mae: 0.0577\n",
            "Epoch 72/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 7.7441e-04 - rmse: 0.0278 - mse: 7.7441e-04 - mae: 0.0220 - val_loss: 0.0061 - val_rmse: 0.0782 - val_mse: 0.0061 - val_mae: 0.0585\n",
            "Epoch 73/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 7.7935e-04 - rmse: 0.0279 - mse: 7.7935e-04 - mae: 0.0221 - val_loss: 0.0063 - val_rmse: 0.0796 - val_mse: 0.0063 - val_mae: 0.0604\n",
            "Epoch 74/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 6.7824e-04 - rmse: 0.0260 - mse: 6.7824e-04 - mae: 0.0208 - val_loss: 0.0061 - val_rmse: 0.0780 - val_mse: 0.0061 - val_mae: 0.0593\n",
            "Epoch 75/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 7.7166e-04 - rmse: 0.0278 - mse: 7.7166e-04 - mae: 0.0220 - val_loss: 0.0063 - val_rmse: 0.0796 - val_mse: 0.0063 - val_mae: 0.0606\n",
            "Epoch 76/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 8.7106e-04 - rmse: 0.0295 - mse: 8.7106e-04 - mae: 0.0234 - val_loss: 0.0063 - val_rmse: 0.0791 - val_mse: 0.0063 - val_mae: 0.0603\n",
            "Epoch 77/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 7.6003e-04 - rmse: 0.0276 - mse: 7.6003e-04 - mae: 0.0216 - val_loss: 0.0061 - val_rmse: 0.0782 - val_mse: 0.0061 - val_mae: 0.0588\n",
            "Epoch 78/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 6.8267e-04 - rmse: 0.0261 - mse: 6.8267e-04 - mae: 0.0207 - val_loss: 0.0061 - val_rmse: 0.0783 - val_mse: 0.0061 - val_mae: 0.0591\n",
            "Epoch 79/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 7.0613e-04 - rmse: 0.0266 - mse: 7.0613e-04 - mae: 0.0210 - val_loss: 0.0065 - val_rmse: 0.0804 - val_mse: 0.0065 - val_mae: 0.0605\n",
            "Epoch 80/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 6.2959e-04 - rmse: 0.0251 - mse: 6.2959e-04 - mae: 0.0198 - val_loss: 0.0062 - val_rmse: 0.0785 - val_mse: 0.0062 - val_mae: 0.0594\n",
            "Epoch 81/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 6.7177e-04 - rmse: 0.0259 - mse: 6.7177e-04 - mae: 0.0205 - val_loss: 0.0062 - val_rmse: 0.0784 - val_mse: 0.0062 - val_mae: 0.0594\n",
            "Epoch 82/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 6.5966e-04 - rmse: 0.0257 - mse: 6.5966e-04 - mae: 0.0204 - val_loss: 0.0061 - val_rmse: 0.0782 - val_mse: 0.0061 - val_mae: 0.0590\n",
            "Epoch 83/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 6.6593e-04 - rmse: 0.0258 - mse: 6.6593e-04 - mae: 0.0208 - val_loss: 0.0062 - val_rmse: 0.0790 - val_mse: 0.0062 - val_mae: 0.0602\n",
            "Epoch 84/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 6.0761e-04 - rmse: 0.0246 - mse: 6.0761e-04 - mae: 0.0196 - val_loss: 0.0063 - val_rmse: 0.0792 - val_mse: 0.0063 - val_mae: 0.0600\n",
            "Epoch 85/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 5.7943e-04 - rmse: 0.0241 - mse: 5.7943e-04 - mae: 0.0190 - val_loss: 0.0061 - val_rmse: 0.0782 - val_mse: 0.0061 - val_mae: 0.0593\n",
            "Epoch 86/200\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 5.8298e-04 - rmse: 0.0241 - mse: 5.8298e-04 - mae: 0.0191 - val_loss: 0.0060 - val_rmse: 0.0777 - val_mse: 0.0060 - val_mae: 0.0586\n",
            "Epoch 87/200\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 5.8593e-04 - rmse: 0.0242 - mse: 5.8593e-04 - mae: 0.0193 - val_loss: 0.0061 - val_rmse: 0.0778 - val_mse: 0.0061 - val_mae: 0.0588\n",
            "Epoch 88/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 5.9893e-04 - rmse: 0.0245 - mse: 5.9893e-04 - mae: 0.0192 - val_loss: 0.0062 - val_rmse: 0.0785 - val_mse: 0.0062 - val_mae: 0.0600\n",
            "Epoch 89/200\n",
            "80/80 [==============================] - 6s 73ms/step - loss: 6.3507e-04 - rmse: 0.0252 - mse: 6.3507e-04 - mae: 0.0200 - val_loss: 0.0059 - val_rmse: 0.0770 - val_mse: 0.0059 - val_mae: 0.0575\n",
            "Epoch 90/200\n",
            "80/80 [==============================] - 6s 74ms/step - loss: 5.8507e-04 - rmse: 0.0242 - mse: 5.8507e-04 - mae: 0.0193 - val_loss: 0.0062 - val_rmse: 0.0785 - val_mse: 0.0062 - val_mae: 0.0587\n",
            "Epoch 91/200\n",
            "79/80 [============================>.] - ETA: 0s - loss: 5.8582e-04 - rmse: 0.0242 - mse: 5.8582e-04 - mae: 0.0191Restoring model weights from the end of the best epoch: 71.\n",
            "80/80 [==============================] - 6s 72ms/step - loss: 5.8644e-04 - rmse: 0.0242 - mse: 5.8644e-04 - mae: 0.0191 - val_loss: 0.0061 - val_rmse: 0.0781 - val_mse: 0.0061 - val_mae: 0.0591\n",
            "Epoch 91: early stopping\n",
            "<keras.callbacks.History object at 0x7f9a1cba4040>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3 Model Evaluation and Results**"
      ],
      "metadata": {
        "id": "5juU0LTR4Ir5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_rmse, test_mse, test_mae  = model.evaluate(x_test_text, y_test, verbose=2)\n",
        "validation_loss, validation_rmse, validation_mse, validation_mae = model.evaluate(x_validation_text, y_val, verbose=2)\n",
        "train_loss, train_rmse, train_mse, train_mae = model.evaluate(x_train_text, y_train, verbose=2)"
      ],
      "metadata": {
        "id": "hOecMJLWwwLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3460a8-e3fd-4497-a4a7-cc94d3aa8e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 - 0s - loss: 0.0059 - rmse: 0.0771 - mse: 0.0059 - mae: 0.0577 - 425ms/epoch - 47ms/step\n",
            "9/9 - 0s - loss: 0.0059 - rmse: 0.0769 - mse: 0.0059 - mae: 0.0577 - 422ms/epoch - 47ms/step\n",
            "65/65 - 3s - loss: 4.9615e-04 - rmse: 0.0223 - mse: 4.9615e-04 - mae: 0.0174 - 3s/epoch - 48ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.predict(x_test_text)\n",
        "# print(result)\n",
        "# print(result[0])"
      ],
      "metadata": {
        "id": "yUEwurDDEvjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb485f14-aff2-4dd4-877b-9739569f7e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 44ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "figure(figsize=(4, 3), dpi=80)\n",
        "plt.scatter(np.array(y_test), result, s=3)\n",
        "# plt.legend()\n",
        "x = [0, 1]\n",
        "y = [0, 1]\n",
        "plt.plot(x, y, color=\"black\")\n",
        "plt.xlabel(var + ' ground truth')\n",
        "plt.ylabel(var + ' prediction')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# plot_history(history)\n"
      ],
      "metadata": {
        "id": "U7js7PUn93Pr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "84360a34-440a-4d64-f5cb-4aa62ca02616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x240 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import nan\n",
        "test = np.array(y_test).T\n",
        "# print(test)\n",
        "predict = np.array(result).T\n",
        "\n",
        "correlation_matrix = np.corrcoef(test, predict)\n",
        "print(correlation_matrix)\n",
        "correlation_xy = correlation_matrix[0,1]\n",
        "r_squared = correlation_xy**2\n",
        "\n",
        "print (r_squared)"
      ],
      "metadata": {
        "id": "OFItpnon9LxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12637601-a4c5-4ee8-955e-ec51da1e052b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.79543965]\n",
            " [0.79543965 1.        ]]\n",
            "0.6327242443289516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4 Store the Model & Train, Validation and Test Results**"
      ],
      "metadata": {
        "id": "8tUa9yk24XkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = pd.DataFrame()\n",
        "idx = 0\n",
        "output.loc[idx, 'train_rmse'] = train_rmse\n",
        "output.loc[idx, 'train_mse'] = train_mse\n",
        "output.loc[idx, 'train_mae'] = train_mae\n",
        "\n",
        "output.loc[idx, 'validation_rmse'] = validation_rmse\n",
        "output.loc[idx, 'validation_mse'] = validation_mse\n",
        "output.loc[idx, 'validation_mae'] = validation_mae\n",
        "\n",
        "output.loc[idx, 'test_rmse'] = test_rmse\n",
        "output.loc[idx, 'test_mse'] = test_mse\n",
        "output.loc[idx, 'test_mae'] = test_mae\n",
        "\n",
        "output.loc[idx, 'r^2'] = r_squared\n",
        "pd.set_option('display.max_columns', None)\n",
        "print(output)\n",
        "output.to_csv('text_unimodal_value.csv')"
      ],
      "metadata": {
        "id": "FaOeAt6gddXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store the model\n",
        "# summarize the loaded model\n",
        "model.summary()\n",
        "# save the best performing model to file\n",
        "model.save('model weight/' + var + '_Text.h5', include_optimizer=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UamqbUVlCV-j",
        "outputId": "6bc7ec4c-b43b-40cb-a435-14f6c319d77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Text_Model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprocessing (KerasLayer)     {'input_word_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128),                                                          \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'encoder_outputs':  28763649    ['preprocessing[0][0]',          \n",
            "                                 [(None, 128, 512),               'preprocessing[0][1]',          \n",
            "                                 (None, 128, 512),                'preprocessing[0][2]']          \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 512),                                                       \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 'default': (None,                                                \n",
            "                                512)}                                                             \n",
            "                                                                                                  \n",
            " text_dropout_after_Bert (Dropo  (None, 512)         0           ['BERT_encoder[0][5]']           \n",
            " ut)                                                                                              \n",
            "                                                                                                  \n",
            " text_dense_last2 (Dense)       (None, 100)          51300       ['text_dropout_after_Bert[0][0]']\n",
            "                                                                                                  \n",
            " text_out1y (Dense)             (None, 1)            101         ['text_dense_last2[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,815,050\n",
            "Trainable params: 28,815,049\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reload the model\n",
        "model_name = 'model weight/' + var + '_Text.h5'\n",
        "Bertmodel = tf.keras.models.load_model(model_name, custom_objects={'KerasLayer': hub.KerasLayer})\n",
        "Bertmodel.summary()\n",
        "\n",
        "result = Bertmodel.predict(x_test_text)\n",
        "\n",
        "test = np.array(y_test).T\n",
        "predict = np.array(result).T\n",
        "\n",
        "correlation_matrix = np.corrcoef(test, predict)\n",
        "print(correlation_matrix)\n",
        "correlation_xy = correlation_matrix[0,1]\n",
        "r_squared = correlation_xy**2\n",
        "\n",
        "print (r_squared)"
      ],
      "metadata": {
        "id": "3-B0bvfb97DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in Bertmodel.layers:\n",
        "    layer.trainable = True\n",
        "    print(layer.name, layer)\n",
        "Bert_weight = Bertmodel.layers[-1].get_weights()[0]\n",
        "Bert_bias = Bertmodel.layers[-1].get_weights()[1]\n",
        "print(Bert_weight)\n",
        "print(len(Bert_weight))\n",
        "print(Bert_bias)"
      ],
      "metadata": {
        "id": "YuZpUUtw-eLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try to get the output\n",
        "layer_name = 'BERT_encoder'\n",
        "layer_output_origin = model.get_layer(layer_name).output\n",
        "# layer_output = layer_output_origin['pooled_output']\n",
        "layer_output = layer_output_origin\n",
        "print(layer_output)\n",
        "print(layer_output['pooled_output'])"
      ],
      "metadata": {
        "id": "zGY2G0rsSRSx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}