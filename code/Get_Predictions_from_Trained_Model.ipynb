{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "gpuClass": "premium",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "var = 'total score'\n",
        "a = 'predictions ' + var + '.csv'\n",
        "print(a)\n",
        "print('predictions total score.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jJxia0TXP5Z",
        "outputId": "4c8f70b7-f2bb-4e70-e1c0-11c27ce856f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions total score.csv\n",
            "predictions total score.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "var = \"total score\"\n",
        "a = \"predictions \" + var + \".csv\"\n",
        "print(a)\n",
        "print(\"predictions total score.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r6E0DG3E1uh",
        "outputId": "1a47bd7a-a457-4783-d703-f5a754478ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions total score.csv\n",
            "predictions total score.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvdTPQfzmnAm",
        "outputId": "255c235d-4174-40d7-c8ec-05020fb56ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May 17 20:06:54 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    25W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DwlxLjxm5fG",
        "outputId": "ec0db4ea-9bb9-4c37-d08f-38fe4b667439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text"
      ],
      "metadata": {
        "id": "63nNfCb2OYUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-models-official"
      ],
      "metadata": {
        "id": "429PQ6QIOYvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*-coding:utf8 -*-\n",
        "import tensorflow as tf\n",
        "# print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib.pyplot import figure\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow.python import keras\n",
        "from keras.layers import Dense, Flatten, Conv2D\n",
        "from keras.optimizers import RMSprop, Adam, SGD\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import Model, Input, layers\n",
        "\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "from keras import Model, Input, layers, regularizers\n",
        "from keras.models import load_model\n",
        "from keras import activations"
      ],
      "metadata": {
        "id": "r9f3jnrspEse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa40ac8-9308-43df-a86a-c3800d227785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "58gTaBEeWt1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/Vehicle Rating Prediction/new_images_with_folder\n",
        "!unzip \"new_images_with_folder.zip\""
      ],
      "metadata": {
        "id": "cl-jkd15XDNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/Vehicle Rating Prediction/new_interior_images_with_folder\n",
        "!unzip \"new_interior_images_with_folder.zip\""
      ],
      "metadata": {
        "id": "ciDby6SDUenR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# change to your personal project address\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/Vehicle Rating Prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjHBjkEcphmW",
        "outputId": "84c3a9e8-5de2-4e30-cf84-ff993aaf4981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/across-attention/total score\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1 Data Processing**"
      ],
      "metadata": {
        "id": "kF2Apvy2bWlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "var = \"total score\"\n",
        "# var = \"safety score\"\n",
        "# var = \"performance score\"\n",
        "# var = \"interior score\"\n",
        "# var = \"critics score\""
      ],
      "metadata": {
        "id": "MACuKGGkFnnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 first we need to get the total score information from the csv file\n",
        "# read info_data\n",
        "file_name = \"parametric data 2571 normalize \" + var + \".csv\"\n",
        "info_data = pd.read_csv(file_name)\n",
        "# get numpy matrix which only contains data (do not contain the title)\n",
        "info_data = np.array(info_data)\n",
        "print(info_data.shape)  # (2571, 303)\n",
        "print(len(info_data))\n",
        "print(info_data.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i5-YuskSHwX",
        "outputId": "0ba624cb-030f-4637-eb9c-2b7932eabfa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2571, 310)\n",
            "2571\n",
            "310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train data shuffle index\n",
        "num1 = 2055\n",
        "idx1 = tf.range(num1)\n",
        "idx1 = tf.random.shuffle(idx1)\n",
        "# print(idx1)\n",
        "# print(idx1[0])\n",
        "with tf.compat.v1.Session():\n",
        "    index1 = idx1.numpy()\n",
        "# print(index1.shape)\n",
        "# print(index1[0])\n",
        "\n",
        "# validation data shuffle index\n",
        "num2 = 258\n",
        "idx2 = tf.range(num2)\n",
        "idx2 = tf.random.shuffle(idx2)\n",
        "# print(idx2)\n",
        "# print(idx2[0])\n",
        "with tf.compat.v1.Session():\n",
        "    index2 = idx2.numpy()\n",
        "# print(index2.shape)\n",
        "# print(index2[0])\n",
        "\n",
        "# test data shuffle index\n",
        "num3 = 258\n",
        "idx3 = tf.range(num3)\n",
        "idx3 = tf.random.shuffle(idx3)\n",
        "# print(idx3)\n",
        "# print(idx3[0])\n",
        "with tf.compat.v1.Session():\n",
        "    index3 = idx3.numpy()\n",
        "# print(index3.shape)\n",
        "# print(index3[0])"
      ],
      "metadata": {
        "id": "JCgUq_QV_a9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the parametric data\n",
        "x_train_tab = np.zeros((num1, 302))\n",
        "y_train_tab = np.zeros((num1, 1))\n",
        "for i in range(num1):\n",
        "    x_train_tab[i, :] = np.array(info_data[index1[i], 2:304], dtype=float)\n",
        "    y_train_tab[i] = np.array(info_data[index1[i], 304], dtype=float)\n",
        "x_train_tab = tf.convert_to_tensor(x_train_tab)\n",
        "y_train_tab = tf.convert_to_tensor(y_train_tab)\n",
        "y_train = y_train_tab\n",
        "print(y_train.shape)\n",
        "\n",
        "x_validation_tab = np.zeros((num2, 302))\n",
        "y_validation_tab = np.zeros((num2, 1))\n",
        "for i in range(num2):\n",
        "    x_validation_tab[i, :] = np.array(info_data[index2[i] + num1, 2:304], dtype=float)\n",
        "    y_validation_tab[i] = np.array(info_data[index2[i] + num1, 304], dtype=float)\n",
        "x_validation_tab = tf.convert_to_tensor(x_validation_tab)\n",
        "y_validation_tab = tf.convert_to_tensor(y_validation_tab)\n",
        "y_validation = y_validation_tab\n",
        "print(y_validation.shape)\n",
        "\n",
        "x_test_tab = np.zeros((num3, 302))\n",
        "y_test_tab = np.zeros((num3, 1))\n",
        "for i in range(num3):\n",
        "    x_test_tab[i, :] = np.array(info_data[index3[i] + num1 + num2, 2:304], dtype=float)\n",
        "    y_test_tab[i] = np.array(info_data[index3[i] + num1 + num2, 304], dtype=float)\n",
        "x_test_tab = tf.convert_to_tensor(x_test_tab)\n",
        "y_test_tab = tf.convert_to_tensor(y_test_tab)\n",
        "y_test = y_test_tab\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jY-su0u_aq-",
        "outputId": "8fa3dc8f-8a47-421f-e9db-b5df8ca0ed6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2055, 1)\n",
            "(258, 1)\n",
            "(258, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the text data\n",
        "var_name = 'data split ' + var\n",
        "\n",
        "sketch1 = pd.read_csv('text_data.csv', encoding='latin1')\n",
        "# print(sketch1.shape)\n",
        "# print(sketch1)\n",
        "# print(sketch1[var])\n",
        "train_df = sketch1[sketch1[var_name] == 1]\n",
        "val_df = sketch1[sketch1[var_name] == 2]\n",
        "test_df = sketch1[sketch1[var_name] == 3]\n",
        "# print(train_df.shape)\n",
        "# print(train_df)\n",
        "\n",
        "sketch2 = train_df.astype({\"text\": str})\n",
        "text1 = list(sketch2['text'])\n",
        "\n",
        "sketch3 = val_df.astype({\"text\": str})\n",
        "text2 = list(sketch3['text'])\n",
        "\n",
        "sketch4 = test_df.astype({\"text\": str})\n",
        "text3 = list(sketch4['text'])\n",
        "\n",
        "\n",
        "train_text = [text1[i] for i in index1]\n",
        "x_train_text = tf.constant(train_text)\n",
        "\n",
        "validation_text = [text2[i] for i in index2]\n",
        "x_validation_text = tf.constant(validation_text)\n",
        "\n",
        "test_text = [text3[i] for i in index3]\n",
        "x_test_text = tf.constant(test_text)\n",
        "# print(len(train_text))\n",
        "# print(train_text[0])"
      ],
      "metadata": {
        "id": "8LSK_6Nw_aYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the exterior image data\n",
        "image = np.zeros((290, 448, 3))\n",
        "x_train = np.zeros((num1, 290, 448, 3))\n",
        "x_validation = np.zeros((num2, 290, 448, 3))\n",
        "x_test = np.zeros((num3, 290, 448, 3))\n",
        "# image = image_data[0]\n",
        "\n",
        "# train data\n",
        "for i in range(num1):\n",
        "    folder_path = r'new_images_with_folder/' + info_data[index1[i]][1]\n",
        "    dirs = os.listdir(folder_path)\n",
        "    print(i)\n",
        "    if len(dirs) > 0:\n",
        "        # only one total picture\n",
        "        dirpath = folder_path + '/' + dirs[0]  # get the angular front view of the car\n",
        "        img = Image.open(dirpath)\n",
        "        img_plt = np.array(img)\n",
        "        x_train[i, :, :, :] = img_plt / 255.0\n",
        "\n",
        "# validation data\n",
        "for i in range(num2):\n",
        "    folder_path = r'new_images_with_folder/' + info_data[index2[i]+num1][1]\n",
        "    dirs = os.listdir(folder_path)\n",
        "    print(i)\n",
        "    if len(dirs) > 0:\n",
        "        # only one total picture\n",
        "        dirpath = folder_path + '/' + dirs[0]  # get the angular front view of the car\n",
        "        img = Image.open(dirpath)\n",
        "        img_plt = np.array(img)\n",
        "        x_validation[i, :, :, :] = img_plt / 255.0\n",
        "\n",
        "# test data\n",
        "for i in range(num3):\n",
        "    folder_path = r'new_images_with_folder/' + info_data[index3[i]+num1+num2][1]\n",
        "    dirs = os.listdir(folder_path)\n",
        "    print(i)\n",
        "    if len(dirs) > 0:\n",
        "        # only one total picture\n",
        "        dirpath = folder_path + '/' + dirs[0]  # get the angular front view of the car\n",
        "        img = Image.open(dirpath)\n",
        "        img_plt = np.array(img)\n",
        "        x_test[i, :, :, :] = img_plt / 255.0\n",
        "\n",
        "x_train_ex_img = tf.convert_to_tensor(x_train)\n",
        "x_validation_ex_img = tf.convert_to_tensor(x_validation)\n",
        "x_test_ex_img = tf.convert_to_tensor(x_test)"
      ],
      "metadata": {
        "id": "MPEzAEyc_ZiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the interior image data\n",
        "image = np.zeros((300, 448, 3))\n",
        "x_train = np.zeros((num1, 300, 448, 3))\n",
        "x_validation = np.zeros((num2, 300, 448, 3))\n",
        "x_test = np.zeros((num3, 300, 448, 3))\n",
        "# image = image_data[0]\n",
        "\n",
        "# train data\n",
        "for i in range(num1):\n",
        "    folder_path = r'new_interior_images_with_folder/' + info_data[index1[i]][1]\n",
        "    dirs = os.listdir(folder_path)\n",
        "    print(i)\n",
        "    if len(dirs) > 0:\n",
        "        # only one total picture\n",
        "        dirpath = folder_path + '/' + dirs[0]  # get the angular front view of the car\n",
        "        img = Image.open(dirpath)\n",
        "        img_plt = np.array(img)\n",
        "        x_train[i, :, :, :] = img_plt / 255.0\n",
        "\n",
        "\n",
        "# validation data\n",
        "for i in range(num2):\n",
        "    folder_path = r'new_interior_images_with_folder/' + info_data[index2[i]+num1][1]\n",
        "    dirs = os.listdir(folder_path)\n",
        "    print(i)\n",
        "    if len(dirs) > 0:\n",
        "        # only one total picture\n",
        "        dirpath = folder_path + '/' + dirs[0]  # get the angular front view of the car\n",
        "        img = Image.open(dirpath)\n",
        "        img_plt = np.array(img)\n",
        "        x_validation[i, :, :, :] = img_plt / 255.0\n",
        "\n",
        "\n",
        "# test data\n",
        "for i in range(num3):\n",
        "    folder_path = r'new_interior_images_with_folder/' + info_data[index3[i]+num1+num2][1]\n",
        "    dirs = os.listdir(folder_path)\n",
        "    print(i)\n",
        "    if len(dirs) > 0:\n",
        "        # only one total picture\n",
        "        dirpath = folder_path + '/' + dirs[0]  # get the angular front view of the car\n",
        "        img = Image.open(dirpath)\n",
        "        img_plt = np.array(img)\n",
        "        x_test[i, :, :, :] = img_plt / 255.0\n",
        "\n",
        "\n",
        "x_train_in_img = tf.convert_to_tensor(x_train)\n",
        "x_validation_in_img = tf.convert_to_tensor(x_validation)\n",
        "x_test_in_img = tf.convert_to_tensor(x_test)"
      ],
      "metadata": {
        "id": "FxhsIzRNUpcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load unimodal model**"
      ],
      "metadata": {
        "id": "KLZ1dWMEbo5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construct MML model\n",
        "adam_optimizer = Adam(learning_rate=0.001)\n",
        "rms_prop_optimizer = RMSprop(learning_rate=0.001)\n",
        "sgd_optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=False)"
      ],
      "metadata": {
        "id": "eQpvhSP982kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the pretrain model\n",
        "\n",
        "\n",
        "# MLP\n",
        "MLPmodel = tf.keras.models.load_model('model weight/' + var + '_Par.h5')\n",
        "# for layer in MLPmodel.layers:\n",
        "#   layer._name = layer._name + \"_b\"\n",
        "MLPmodel.summary()\n",
        "\n",
        "# Bert\n",
        "model_name = 'model weight/' + var + '_Text.h5'\n",
        "Bertmodel = tf.keras.models.load_model(model_name, custom_objects={'KerasLayer': hub.KerasLayer})\n",
        "# for layer in Bertmodel.layers:\n",
        "#   layer._name = layer._name + \"_c\"\n",
        "Bertmodel.summary()\n",
        "\n",
        "# Ex_CNN\n",
        "Ex_CNNmodel = tf.keras.models.load_model('model weight/' + var + '_Ex_Img.h5')\n",
        "# for layer in Ex_CNNmodel.layers:\n",
        "#   layer._name = layer._name + \"_a\"\n",
        "Ex_CNNmodel.summary()\n",
        "\n",
        "# In_CNN\n",
        "In_CNNmodel = tf.keras.models.load_model('model weight/' + var + '_In_Img.h5')\n",
        "# for layer in In_CNNmodel.layers:\n",
        "#   layer._name = layer._name + \"_d\"\n",
        "In_CNNmodel.summary()"
      ],
      "metadata": {
        "id": "eezq3Eus82hd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af3de107-8d1f-42f9-cefb-ecdb555f35c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Tabular_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " tab_dense1 (Dense)          (None, 302)               91506     \n",
            "                                                                 \n",
            " tab_dropout1 (Dropout)      (None, 302)               0         \n",
            "                                                                 \n",
            " tab_dense2 (Dense)          (None, 100)               30300     \n",
            "                                                                 \n",
            " tab_dense3 (Dense)          (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,907\n",
            "Trainable params: 121,907\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Text_Model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprocessing (KerasLayer)     {'input_word_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'encoder_outputs':  28763649    ['preprocessing[0][0]',          \n",
            "                                 [(None, 128, 512),               'preprocessing[0][1]',          \n",
            "                                 (None, 128, 512),                'preprocessing[0][2]']          \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 512),                                                       \n",
            "                                 'default': (None,                                                \n",
            "                                512),                                                             \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 512)}                                                \n",
            "                                                                                                  \n",
            " text_dropout_after_Bert (Dropo  (None, 512)         0           ['BERT_encoder[0][5]']           \n",
            " ut)                                                                                              \n",
            "                                                                                                  \n",
            " text_dense_last2 (Dense)       (None, 100)          51300       ['text_dropout_after_Bert[0][0]']\n",
            "                                                                                                  \n",
            " text_out1y (Dense)             (None, 1)            101         ['text_dense_last2[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,815,050\n",
            "Trainable params: 28,815,049\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **get prediction result**"
      ],
      "metadata": {
        "id": "TS6RA4PNdPOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result1 = MLPmodel.predict(x_train_tab)\n",
        "\n",
        "result2 = Bertmodel.predict(x_train_text)\n",
        "\n",
        "result3 = Ex_CNNmodel.predict(x_train_ex_img)\n",
        "\n",
        "result4 = In_CNNmodel.predict(x_train_in_img)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXjZ6KV9dO3L",
        "outputId": "f9cadc4d-028c-4f85-9440-e768d55d8873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65/65 [==============================] - 0s 2ms/step\n",
            "65/65 [==============================] - 5s 64ms/step\n",
            "65/65 [==============================] - 5s 70ms/step\n",
            "65/65 [==============================] - 5s 70ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result5 = MLPmodel.predict(x_test_tab)\n",
        "\n",
        "result6 = Bertmodel.predict(x_test_text)\n",
        "\n",
        "result7 = Ex_CNNmodel.predict(x_test_ex_img)\n",
        "\n",
        "result8 = In_CNNmodel.predict(x_train_in_img)"
      ],
      "metadata": {
        "id": "l7PtDPlDCDlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = np.zeros((2313, 5))\n",
        "for i in range(2055):\n",
        "    matrix[i, 0] = result1[i]\n",
        "    matrix[i, 1] = result2[i]\n",
        "    matrix[i, 2] = result3[i]\n",
        "    matrix[i, 3] = result4[i]\n",
        "    matrix[i, 4] = y_train[i]\n",
        "for i in range(258):\n",
        "    matrix[i+2055, 0] = result5[i]\n",
        "    matrix[i+2055, 1] = result6[i]\n",
        "    matrix[i+2055, 2] = result7[i]\n",
        "    matrix[i+2055, 3] = result8[i]\n",
        "    matrix[i+2055, 4] = y_test[i]"
      ],
      "metadata": {
        "id": "BeZjyv9rdYQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv"
      ],
      "metadata": {
        "id": "ZXxkWr2fjIie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers = ['MLP', 'Bert', 'Ex_CNN', 'In_CNN', 'True Value']\n",
        "file_name1 = 'predictions_' + var + '.csv'\n",
        "with open(file_name1, 'w', newline='') as f:\n",
        "    f_csv = csv.writer(f)\n",
        "    f_csv.writerow(headers)\n",
        "    f_csv.writerows(matrix)\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "0dKeRdekjFf3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}